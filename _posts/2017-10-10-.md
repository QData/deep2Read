---
layout: post
title: Reliable Applications I - Understanding
desc: 2017-W8
tags:
- 3Reliable
categories: 2017Course
---



| Presenter | Papers | Information| OurPresentation |
| -----: | ----------: | :----- | :----- |
| Rita | Learning Important Features Through Propagating Activation Differences, ICML17 | [PDF](https://arxiv.org/abs/1704.02685) | [PDF]({{site.baseurl}}/talks/20171010-Rita.pdf) |
| GaoJi  | Examples are not Enough, Learn to Criticize! Model Criticism for Interpretable Machine Learning, NIPS16 | [PDF](http://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf) | [PDF]({{site.baseurl}}/talks/20171010-Ji.pdf) |
| Rita | Learning Kernels with Random Features, Aman Sinha*; John Duchi, | [PDF](https://stanford.edu/~jduchi/projects/SinhaDu16.pdf) | [PDF]({{site.baseurl}}/talks/20170907-Rita.pdf) |


> #### Learning Kernels with Random Features / John Duchi NIPS2016
>> Randomized features provide a computationally efficient way to approximate kernel machines in machine learning tasks. However, such methods require a user-defined kernel as input. We extend the randomized-feature approach to the task of learning a kernel (via its associated random features). Specifically, we present an efficient optimization problem that learns a kernel in a supervised manner. We prove the consistency of the estimated kernel as well as generalization bounds for the class of estimators induced by the optimized kernel, and we experimentally evaluate our technique on several datasets. Our approach is efficient and highly scalable, and we attain competitive results with a fraction of the training cost of other techniques.



> ####  


> ####  



> ####  