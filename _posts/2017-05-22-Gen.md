---
layout: post
title: Generative17- Generative Deep Networks 
desc: 2017-team
tags:
- 5Generative
categories: 2017Reads
---


| Presenter | Papers | Paper URL| Our Slides |
| -----: | -------------------------------------: | :----- | :----- |
| Tobin |  Energy-Based Generative Adversarial Network [^1] | [PDF](https://arxiv.org/abs/1609.03126) |  [PDF]({{site.baseurl}}/MoreTalksTeam/Un17/Tobin-EnergyGAN.pdf) | 
| Jack |  Three Deep Generative Models |  [PDF]() |  [PDF]({{site.baseurl}}/MoreTalksTeam/Jack/04_08_16-JackThreeDeepGenerativeModels.pdf) | 


[^1]: <sub><sup> Energy-Based Generative Adversarial Network, Junbo Zhao, Michael Mathieu, Yann LeCun (Submitted on 11 Sep 2016 (v1), last revised 6 Mar 2017 (this version, v4))/ We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images. </sup></sub>

