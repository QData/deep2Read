---
layout: post
title: Optimization II -  DNN for Optimization
desc: 2017-W11
tags:
- 4Optimization
categories: 2017Course
---



| Presenter | Papers | Paper URL| Our Slides |
| -----: | ---------------------------: | :----- | :----- |
| GaoJi | Neural Architecture Search with Reinforcement Learning, ICLR17 [^1] | [PDF](https://openreview.net/pdf?id=r1Ue8Hcxg) | [PDF]({{site.baseurl}}/talks/20171102-Ji.pdf) |
| Ceyer | Learning to learn [^2] | [DLSS17video](http://videolectures.net/deeplearning2017_de_freitas_learning_to_learn/) | [PDF]({{site.baseurl}}/talks/20171102-Ceyer.pdf) |
| Beilun |   Optimization as a Model for Few-Shot Learning, ICLR17 [^3] | [PDF](https://openreview.net/pdf?id=rJY0-Kcll) + [More](https://github.com/songrotek/Meta-Learning-Papers)| [PDF]({{site.baseurl}}/talks/20171102-beilun.pdf) |
| Anant |  Neural Optimizer Search with Reinforcement Learning, ICML17 [^4] |[PDF](http://proceedings.mlr.press/v70/bello17a/bello17a.pdf) | [PDF]({{site.baseurl}}/talks/20171109-Anant.pdf) |

[^1]: <sub><sup>  Neural Optimizer Search with Reinforcement Learning, ICML17 Irwan Bello, Barret Zoph, Vijay Vasudevan, Quoc V. Le / We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string in a domain specific language that describes a mathematical update equation based on a list of primitive functions, such as the gradient, running average of the gradient, etc. The controller is trained with Reinforcement Learning to maximize the performance of a model after a few epochs. On CIFAR-10, our method discovers several update rules that are better than many commonly used optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two new optimizers, named PowerSign and AddSign, which we show transfer well and improve training on a variety of different tasks and architectures, including ImageNet classification and Google's neural machine translation system. </sup></sub>



[^2]: <sub><sup>  Neural Architecture Search with Reinforcement Learning, ICLR17 , Barret Zoph, Quoc V. Le / Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. </sup></sub>



[^3]: <sub><sup> Learning to learn / DLSS17 / Learning to learn without gradient descent by gradient descent / Yutian Chen, Matthew W Hoffman, Sergio GÃ³mez Colmenarejo, Misha Denil, Timothy P Lillicrap, Matt Botvinick, Nando de Freitas/ We learn recurrent neural network optimizers trained on simple synthetic functions by gradient descent. We show that these learned optimizers exhibit a remarkable degree of transfer in that they can be used to efficiently optimize a broad range of derivative-free black-box functions, including Gaussian process bandits, simple control objectives, global optimization benchmarks and hyper-parameter tuning tasks. Up to the training horizon, the learned optimizers learn to tradeoff exploration and exploitation, and compare favourably with heavily engineered Bayesian optimization packages for hyper-parameter tuning. </sup></sub>



[^4]: <sub><sup> Optimization as a Model for Few-Shot Learning, ICLR17 / achin Ravi, Hugo Larochelle/ Abstract: Though deep neural networks have shown great success in the large data domain, they generally perform poorly on few-shot learning tasks, where a model has to quickly generalize after seeing very few examples from each class. The general belief is that gradient-based optimization in high capacity models requires many iterative steps over many examples to perform well. Here, we propose an LSTM-based meta-learner model to learn the exact optimization algorithm used to train another learner neural network in the few-shot regime. The parametrization of our model allows it to learn appropriate parameter updates specifically for the scenario where a set amount of updates will be made, while also learning a general initialization of the learner network that allows for quick convergence of training. We demonstrate that this meta-learning model is competitive with deep metric-learning techniques for few-shot learning. </sup></sub>