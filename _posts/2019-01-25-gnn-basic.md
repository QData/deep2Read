---
layout: post
title: GNN Basics I - Deep Learning Advances on Graphs 
desc: 2019-W1
term: 2019sCourse
categories:
- 2Graphs
- 0Basics
- 8Scalable
tags: [invariant, scalable, embedding]
---




| Presenter | Papers | Paper URL| Our Notes |
| -----: | -------------------------------------: | :----- | :----- |
<!--header-->
| Basics | GraphSAGE: Large-scale Graph Representation Learning  by Jure Leskovec Stanford University  |  [URL](http://www.ipam.ucla.edu/abstract/?tid=14555&pcode=DLT2018) + [PDF](https://papers.nips.cc/paper/6703-inductive-representation-learning-on-large-graphs.pdf) |  | 
| Basics  | Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering by Xavier Bresson  |  [URL](http://www.ipam.ucla.edu/abstract/?tid=14506&pcode=DLT2018) + [PDF](http://helper.ipam.ucla.edu/publications/dlt2018/dlt2018_14506.pdf) |  Ryan [Pdf]({{site.baseurl}}/talks2019/19scribeNotes/2019-02-14-Ryan-Note.pdf) | 
| Basics| Gated Graph Sequence Neural Networks by Microsoft Research  |  [URL](https://www.youtube.com/watch?v=cWIeTMklzNg) + [PDF](https://arxiv.org/abs/1511.05493) |  Faizan [Pdf]({{site.baseurl}}/talks2019/19scribeNotes/20190201Fazan.pdf) |
| Basics | DeepWalk - Turning Graphs into Features via Network Embeddings  |  [URL](https://www.youtube.com/watch?v=aZNtHJwfIVg) + [PDF](http://www.perozzi.net/publications/14_kdd_deepwalk.pdf)| | 
| Basics |   Spectral Networks and Locally Connected Networks on Graphs [^1] | [Pdf](https://arxiv.org/abs/1312.6203) | GaoJi [slides]({{site.baseurl}}/talks2019/19sCourse/20190208-Ji-SpectralGraphTheory.pdf) + Bill [Pdf]({{site.baseurl}}/talks2019/19scribeNotes/20190208-Bill-SpectralNetworks.pdf) | 
| Basics |  A Comprehensive Survey on Graph Neural Networks/ Graph Neural Networks: A Review of Methods and Applications   |   [Pdf](https://arxiv.org/pdf/1901.00596.pdf) | Jack [Pdf]({{site.baseurl}}/talks2019/19sCourse/20190208-Jack-GNN_Review.pdf)   |
| GCN |  Semi-Supervised Classification with Graph Convolutional Networks | [Pdf](https://arxiv.org/abs/1609.02907) | Jack [Pdf]({{site.baseurl}}/talks2019/19sCourse/20190301-Jack-GCN.pdf)  | 


<!--excerpt.start-->
[^1]: <sub><sup> Some Relevant Notes from [URL](https://mathoverflow.net/questions/231987/why-decompose-a-function-with-eigenvectors-of-laplace-operator). On periodic domain, people always use Fourier basis, which eigenvectors of Laplace operator. On sphere, people use spherical harmonics, which also are eigenvectors of Laplace operator. In applied science, people decompose functions on a graph using eigenvectors of graph laplacian. Why are these basis preferred? The exponentials used in Fourier series are eigenvalues of shifts, and thus of any operator commuting with shifts, not just Laplacian. Similarly, spherical harmonics carry irreducible representations of ùëÜùëÇ(3) and so they are eigenfunctions of any rotationally invariant operator. If the underlying space has symmetries, it's no wonder that a basis respecting those symmetries has some nice properties. </sup></sub>

