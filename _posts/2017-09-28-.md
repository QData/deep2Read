---
layout: post
title: Structure IV - DNN with Attention 2
desc: W6
tags:
- 2Structures
---



| Presenter | Papers | Information| OurPresentation |
| -----: | ----------: | :----- | :----- |
| Jack  |  Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain, ICLR17 | [PDF](https://arxiv.org/abs/1510.02879)|
| Arshdeep | Bidirectional Attention Flow for Machine Comprehension, ICLR17 | [PDF](https://arxiv.org/abs/1611.01603) + [code](https://github.com/allenai/bi-att-flow)|
|  | An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax, ICLR17 | [PDF](https://arxiv.org/abs/1611.01886)|
| Ceyer | Image-to-Markup Generation with Coarse-to-Fine Attention, ICML17 |[PDF](http://lstm.seas.harvard.edu/latex/) + [code](https://github.com/harvardnlp/im2markup) |
| ChaoJiang |  Can Active Memory Replace Attention? ; Samy Bengio, NIPS16 | [PDF](https://arxiv.org/abs/1610.08613)  |
