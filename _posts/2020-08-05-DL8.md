---
title: Interpretable Deep Learning   
desc: 2020-W8
term: 2020team
categories:
- 3Reliable
tags: [ Interpretable, black-box, casual, attention, shapley, concept]  
---



| Index | Papers |  Our Slides |
| :---- | -------------------------------------: | :------------------------------------- |
|0|  A survey on Interpreting Deep Learning Models| [Eli Survey]({{site.baseurl}}/deep2reproduce/2020trust/Eli-Interpreting_DL_Models.pdf)
| | Interpretable Machine Learning: Definitions,Methods, Applications | [Arsh Survey]({{site.baseurl}}/talkArsh-A19/20190903-BinYuInterpretableReview.pdf) |
| 1| Explaining Explanations: Axiomatic Feature Interactions for Deep Networks | [Arsh Survey]({{site.baseurl}}/talkArsh-A19/03132020-IntegratedHessians.pdf) | 
| 2| Shapley Value review  | [Arsh Survey]({{site.baseurl}}/talkArsh-A19/20190614-ShapleyReview.pdf) | 
| | L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data |  [Bill Survey]({{site.baseurl}}/talks-mb2019/Bill19.10.11_LC_Shapley.pdf) |
| | Consistent Individualized Feature Attribution for Tree Ensembles |[bill Survey]({{site.baseurl}}/talks-mb2019/Bill19.10.19_TreeShapley.pdf) | 
| | Summary for A value for n-person games | [Pan Survey]({{site.baseurl}}/deep2reproduce/2020trust/Pan-Shapley.pdf) |
| | L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data | [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-L-Shapley_and_C-Shapley_presentation.pdf) |
| 3| Hierarchical Interpretations of Neural Network Predictions|  [Arsh Survey]({{site.baseurl}}/talkArsh-A19/20190903-BinYuACD.pdf) |
| | Hierarchical Interpretations of Neural Network Predictions | [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-ACD.pdf) |
| 4| Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs | [Arsh Survey]({{site.baseurl}}/talkArsh-A19/20190903-BinYuCD.pdf) |
| | [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-CD_presentation.pdf) |
| 5 |  Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models | [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-Towards_Hierarchical_Importance_Attribution.pdf) |
 | | |  [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Hierarchical_interpretations_for_neural_network_predictions.pdf) |
 | | Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection | [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Generating_Hierarchical_Explanations_on_Text_Classification_via_Feature_Interaction_Detection.pdf) | 
| 6|  This Looks Like That: Deep Learning for Interpretable Image Recognition | [Pan Survey]({{site.baseurl}}/deep2reproduce/2020trust/Pan-This_Looks_Like_That_Deep_Learning_for_Interpretable_Image_Recognition.pdf) |
| 7|  AllenNLP Interpret|  [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-AllenNLP_presentation.pdf) |
|8 |  DISCOVERY OF NATURAL LANGUAGE CONCEPTS IN INDIVIDUAL UNITS OF CNNs | [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-Concept_Alignment_presentation.pdf) |
|9 |  How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations |  [Rishab Survey]({{site.baseurl}}/deep2reproduce/2020trust/Rishab-How_does_BERT_Answer_Questions_presentation.pdf) |
|10 |  Attention is not Explanation|  [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Attention_is_not_Explanation.pdf) |
| | | [Pan Survey]({{site.baseurl}}/deep2reproduce/2020trust/pan-Attention_is_not_not_Explanation_.pdf) |
| 11|  Axiomatic Attribution for Deep Networks | [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Axiomatic_Attribution_for_Deep_Networks.pdf) |
|12 |  Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization | [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Grad-CAM_Visual_Explanations_from_Deep_Networks_via_Gradient-based_Localization.pdf) |
|13 |  Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifier | [Sanchit Survey]({{site.baseurl}}/deep2reproduce/2020trust/Sanchit-Learning_Variational_Word_Masks_to_Improve_the_Interpretability_of_Neural_Text_Classifier.pdf) |
|14 |  “Why Should I Trust You?”Explaining the Predictions of Any Classifier | [Yu Survey]({{site.baseurl}}/deep2reproduce/2020trust/Yu-LIME.pdf) |
| 15|  INTERPRETATIONS ARE USEFUL: PENALIZING EXPLANATIONS TO ALIGN NEURAL NETWORKS WITH PRIOR KNOWLEDGE | [Pan Survey]({{site.baseurl}}/deep2reproduce/2020trust/pan-interpretation-are-useful.pdf) |