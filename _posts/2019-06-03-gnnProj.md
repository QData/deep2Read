---
layout: post
title: BERT Basics 
desc: 2019-team
categories: 2019Reads
tags:
- 7Graphs
tricks: self-attention, scalable
---



| Presenter | Papers | Paper URL| Our Slides | 
| -----: | -------------------------------: | :----- | :----- | 
| Jack | Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling | | |
| Jack | Generating Long Sequences with Sparse Transformers| [PDF](https://arxiv.org/abs/1904.10509) | |