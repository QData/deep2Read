---
layout: post
title: Reliable17-Secure Machine Learning
desc: 2017-team
categories: 2017Reads
tags:
- 3Reliable
---



| Presenter | Papers | Information| OurPresentation |
| -----: | ----------: | :----- | :----- |
| Tobin | Summary of A few Papers on: Machine Learning and Cryptography, (e.g., learning to Protect Communications with Adversarial Neural Cryptography) | [PDF](https://arxiv.org/abs/1610.06918) |  [PDF]({{site.baseurl}}/MoreTalksTeam/Un17/Tobin-CryptoML.pdf) |
| Tobin |  Privacy Aware Learning (NIPS12) | [PDF](https://web.stanford.edu/~jduchi/projects/DuchiJoWa12_nips.pdf) |  [PDF]({{site.baseurl}}/MoreTalksTeam/Un17/Tobin-DuchiPrivacyLearning.pdf) | 
| Tobin |  Can Machine Learning be Secure?(2006) | [PDF](http://bnrg.cs.berkeley.edu/~adj/publications/paper-files/asiaccs06.pdf) |  [PDF]({{site.baseurl}}/MoreTalksTeam/Un17/Tobin-SecureLearning.pdf)  | 


> #### > Learning to protect communications with adversarial neural cryptography Abadi & Anderson, arXiv 2016
>> We ask whether neural networks can learn to use secret keys to protect information from other neural networks.  Specifically, we focus on ensuring confidentiality properties in a multiagent system, and we specify those properties in terms of an adversary.  Thus, a system may consist of neural networks named Alice and Bob, and we aim to limit what a third neural network named Eve learns from eavesdropping on the communication between Alice and Bob. We do not prescribe specific cryptographic algorithms to these neural networks; instead, we train end-to-end, adversarially. We demonstrate that the neural networks can learn how to perform forms of encryption and decryption, and also how to apply these operations selectively in order to meet confidentiality goals.



#### > Privacy Aware Learning (NIPS12) / John C. Duchi, Michael I. Jordan, Martin J. Wainwright
>> We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner. In this local privacy framework, we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures. As a consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility, as measured by convergence rate, of any statistical estimator or learning procedure.


 
