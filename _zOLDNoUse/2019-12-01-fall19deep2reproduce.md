---
layout: post
title: A general survey
desc: 2019-fall Course Students
term: 2019fCourse
categories:
- 1Theoretical
tags: [ generative, training ]
---


{% assign filedir = 'https://github.com/qiyanjun/deep2reproduce/blob/master/2019Fall/' %}




|Team INDEX     |Title  & Link  | Our Slide |  Tags | 
|------|----------------------------|----------|----------|
|1   | [Safe Reinforcement Learning via Shielding](https://arxiv.org/abs/1708.08611)|  [OurSlide]( {{ filedir | append: 'T1_Hildebrandt, Carl_Safe Reinforcement Learning via Shielding.pdf' }} ) | RL, safety, verification|
|2   | [Empirical Study of Example Forgetting During Deep Neural Network Learning](https://arxiv.org/abs/1812.05159)|  [OurSlide]( {{ filedir | append: 'T2-Pattarabanjird, Tanyaporn_Empirical Study of Example Forgetting During Deep Neural Network Learning.pdf' }}  ) | Sample-selection, forgetting |
|3  | [Deletion-Robust Submodular Maximization: Data Summarization with Privacy and Fairness Constraints](http://proceedings.mlr.press/v80/kazemi18a.html)|  [OurSlide]( {{ filedir | append: 'T3_Musti, Rohit(rm3qg_Data Summarization with Privacy and Fairness.pdf' }} ) | submodular, coreset, safety |
|4 | [Cognitive Scheduler for Heterogeneous High Performance Computing System](https://www.cse.msu.edu/~zhaoxi35/DRL4KDD/10.pdf)|  [OurSlide]( {{ filedir | append: 'T4_Venkataswamy, Vanamala(vv3xu_Cognitive Scheduler for Heterogeneous High Performance.pdf' }} ) | system-application |
|5   | [Deep Structured Prediction with Nonlinear Output Transformations](https://arxiv.org/abs/1811.00539)|  [OurSlide]( {{ filedir | append: 'T5_sc3hn_gz5hp_Deep Structured Prediction.pdf' }} ) | structured |
|6   | [Decision Boundary Analysis of Adversarial Examples](https://openreview.net/forum?id=BkpiPMbA-)|  [OurSlide]( {{ filedir | append: 'T6_Zhou, Xugui(xz6cz_Decision Boundary Analysis of Adversarial Example.pdf' }} ) | adversarial-examples |
|8   | [Robustness may be at odds with accuracy](https://arxiv.org/abs/1805.12152)|  [OurSlide]( {{ filedir | append: 'T8_Liu, Zetian(zl4dc_Robustness may be at odds with accuracy.pdf' }} ) | robustness, theoretical |
|9   | [How SGD Selects the Global Minima in over-parameterized Learning](https://papers.nips.cc/paper/8049-how-sgd-selects-the-global-minima-in-over-parameterized-learning-a-dynamical-stability-perspective)|  [OurSlide]( {{ filedir | append: 'T9_Bamrara, Rishab(rb6xj_How SGD Selects the Global Minima.pdf' }} ) | theoretical, optimization |
|10   | [ Escaping Saddles with Stochastic Gradients ](https://arxiv.org/abs/1803.05999)|  [OurSlide]( {{ filedir | append: 'T10_kd4wa+dc9db+yl5nx+an2adv_ESCAPING SADDLES.pdf' }} ) | theoretical, optimization |
|11   | [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751)|  [OurSlide]( {{ filedir | append: 'T11_Schoch, Stephanie(sns2gr_Parameter-Efficient Transfer.pdf' }} ) | meta, BERT, text|
|12   | [Large Margin Deep Networks for Classification](https://arxiv.org/abs/1803.05598)|  [OurSlide]( {{ filedir | append: 'T12_Sinha, Sanchit(ss7mu_largeMarginDNN.pdf' }} ) | large-margin |
|13   | [To What Extent Do Different Neural Networks Learn the Same Representation](https://arxiv.org/abs/1810.11750)|  [OurSlide]( {{ filedir | append: 'T13_Sudhakar, Mohit(ms5sw_Do Different Neural Networks Learn the Same Representation.pdf' }} ) | theoretical, subspace |
|14   | [CAN: Creative Adversarial Networks Generating “Art”](https://arxiv.org/abs/1706.07068)|  [OurSlide]( {{ filedir | append: 'T14_Ashe, William(wa6gz_creative-GAN.pdf' }} ) | GAN, generative |
|15   | [Wide Activation for Efficient and Accurate Image Super-Resolution](https://arxiv.org/abs/1808.08718)|  [OurSlide]( {{ filedir | append: 'T15_WideActivation_SISR_Skynet_JacobDineen_JD5ED_ Wide Activation.pdf' }} ) | 2Architecture, CNN |
|17   | [Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks](https://arxiv.org/abs/1708.08611)|  [OurSlide]( {{ filedir | append: 'T17_Elsey, Andrew(ae8rh_Ordered Neurons.pdf' }} ) | 2Architecture, RNN |
|18   | [Towards Reverse-Engineering Black-Box Neural Networks](https://arxiv.org/abs/1711.01768)|  [OurSlide]( {{ filedir | append: 'T18_Chen, Hannah(yc4dx_reverseEngineeringBlackBox.pdf' }} ) | meta, model-as-sample, safety, privacy |
|19   | [On the Information Bottleneck Theory of Deep Learning](https://openreview.net/forum?id=ry_WPG-A-)|  [OurSlide]( {{ filedir | append: 'T19_Luo, Zhidan(zl6de_INFORMATION BOTTLENECK.pdf' }} ) | theory, informax |
|20   | [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913)|  [OurSlide]( {{ filedir | append: 'T20_Du, Yu(yd2am_Visualizing the Loss Landscape.pdf' }} ) | normalization, theory |
|21   | [Using Pre-Training Can Improve Model Robustness and Uncertainty ](https://arxiv.org/abs/1901.09960)|  [OurSlide]( {{ filedir | append: 'T21_Wang, Clare(rw9fs_Pre-Training Can Improve Model Robustness and Uncertainty.pdf' }} ) | training, analysis |
|22  | [Deep Asymmetric Multi-task Feature Learning](http://proceedings.mlr.press/v80/lee18d/lee18d.pdf)|  [OurSlide]( {{ filedir | append: 'T22_Yao, David(sy8wg_Asymmetric Multi-task.pdf' }} ) | meta, regularization |
|23   | [The Odds are Odd: A Statistical Test for Detecting Adversarial Examples](https://arxiv.org/abs/1902.04818)|  [OurSlide]( {{ filedir | append: 'T23_Stein, Meriel(ms7nk_Detecting Adversarial Examples.pdf' }} ) | adversarial-examples |
|24   | [Norm matters: efficient and accurate normalization schemes in deep networks](https://arxiv.org/abs/1803.01814)|  [OurSlide]( {{ filedir | append: 'T24_Peddireddy, Akhil Sai(ap3ub_Norm Matters.pdf' }} ) | normalization, theory  |
|25  | [Learning how to explain neural networks: PatternNet and PatternAttribution](https://openreview.net/forum?id=Hkn7CBaTW)|  [OurSlide]( {{ filedir | append: 'T25_Jung, Chijung(cj5kd_Learning how to explain neural networks.pdf' }} ) | Attribution, Interpretable |
|26   | [Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation](https://arxiv.org/abs/1804.08069)|  [OurSlide]( {{ filedir | append: 'T26_sl2kd_Interpretable Neural Dialog Generation.pdf' }} ) | encoder-decoder, dialog, generative, VAE, Interpretable |
|27   | [Implicit Acceleration by Overparameterization](https://arxiv.org/abs/1802.06509)|  [OurSlide]( {{ filedir | append: 'T27_Luo, Tianyang(tl2sf_Implicit Acceleration by Overparameterization.pdf' }} ) | optimization, analysis, theory |
|28  | [Processing of missing data by neural networks](https://arxiv.org/abs/1805.07405)|  [OurSlide]( {{ filedir | append: 'T28_SuYiwen(ys5kh_missingDataByNN.pdf' }} ) | imputation |
|29  | [Select Via Proxy: Efficient Data Selection For Training Deep Networks](https://arxiv.org/abs/1906.11829)|  [OurSlide]( {{ filedir | append: 'T29_Cascante Bonilla, Paola(pc9za_Select Via Proxy_data4train.pdf' }} ) | Sample-selection|
|31   | [Detecting Statistical Interactions from Neural Network Weights](https://arxiv.org/abs/1705.04977)|  [OurSlide]( {{ filedir | append: 'T31_Amiridi, Magda(ma7bx_Detecting Statistical Interactions from Neural Network Weights.pdf' }} ) | Interpretable, Relational |
|32   | [Which Training Methods for GANs do actually Converge](https://arxiv.org/abs/1801.04406)|  [OurSlide]( {{ filedir | append: 'T32Cheng, Kaiming(kc4jd_WhyTrainGANconverge.pdf' }} ) | convergence, optimization, GAN , generative |
|33  | [The High-Dimensional Geometry of Binary Neural Networks](https://arxiv.org/abs/1705.07199)|  [OurSlide]( {{ filedir | append: 'T33_Sharifi, Abdolrasoul(as3mx_HIGH-DIMENSIONAL GEOMETRY_BinaryNN.pdf' }} ) | Quantization, binarization, scalable |
|34  | [Modern Neural Networks Generalize on Small Data Sets](https://papers.nips.cc/paper/7620-modern-neural-networks-generalize-on-small-data-sets)|  [OurSlide]( {{ filedir | append: 'T34_Song, Tairan(ts2ww_Neural Networks Generalize on Small Data Sets.pdf' }} ) | small-data, analysis, 2Architecture, ensemble |

