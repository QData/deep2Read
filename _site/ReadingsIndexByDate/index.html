<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Readings ByDate &middot; Deep Learning 2Read
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/deep2Read/public/css/poole.css">
  <link rel="stylesheet" href="/deep2Read/public/css/syntax.css">
  <link rel="stylesheet" href="/deep2Read/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Rubik" >

  <!-- Icons -->
  <link rel="shortcut icon" href="/deep2Read/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/deep2Read/atom.xml">

</head>


  <body class="theme-base-06">

  	<!--<body class="theme-base-08">
    <body class="theme-gradient">
    <body class="theme-base-09">
	<body class="layout-reverse">-0-->

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/deep2Read/">
          Deep Learning 2Read
        </a>
      </h1> <br><br>
      <p class="lead">A List of Deep Learning Papers We Read:</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/deep2Read/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//About/">Course Information</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//Basic2LearnDeep/">Basic Readings</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//Potential2Read/">Potential Readings</a>
          
        
      
        
          
            <a class="sidebar-nav-item active" href="/deep2Read//ReadingsIndexByDate/">Readings ByDate</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/deep2Read//ReadingsIndexByTags/">Readings ByTag</a>
          
        
      
        
      
        
          
        
      
      <br>
      <a class="sidebar-nav-item" href="https://github.com/QData/deep2Read" target="_blank" >Site GitHub</a>
      <a class="sidebar-nav-item" href="http://www.cs.virginia.edu/yanjun/" target="_blank" >UVA Qdata Lab</a>
      <p>&copy;  <a href="https://twitter.com/Qdatalab" data-widget-id="459649185759764482">Tweets by @Qdatalab</a></p>

    </nav>

  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Our Reviews of Deep Learning Readings by Date-Read</h1>
  <div class="posts">

  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/12/05/">
        RL V - RL with varying Applications
      </a>
    </h1>

    <span class="post-date">- 05 Dec 2017</span>

    <ul>
  <li>Deep Value Networks Learn to Evaluate and Iteratively Refine
Structured Outputs, Michael Gygli, Mohammad Norouzi, Anelia Angelova</li>
  <li>Distral: Robust Multitask Reinforcement Learning,
https://arxiv.org/pdf/1707.04175.pdf</li>
  <li>Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential
Prediction, Wen Sun, Arun Venkatraman, Geoffrey J. Gordon, Byron Boots,
J. Andrew Bagnell ; PMLR 70:3309-3318</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/30/">
        RL IV - RL with varying structures
      </a>
    </h1>

    <span class="post-date">- 30 Nov 2017</span>

    <ul>
  <li>The Predictron: End-to-End Learning and Planning, David Silver, Hado
van Hasselt, Matteo Hessel, Tom Schaul, Arthur Guez, Tim Harley, Gabriel
Dulac-Arnold, David Reichert, Neil Rabinowitz, Andre Barreto, Thomas Degris</li>
  <li>FeUdal Networks for Hierarchical Reinforcement Learning, Sasha
Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Hees, Max Jaderberg,
David Silver, Koray Kavukcuoglu</li>
  <li>Reinforcement Learning with Unsupervised Auxiliary Tasks, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/28/">
        RL III - Basic tutorial RLSS17 (2)
      </a>
    </h1>

    <span class="post-date">- 28 Nov 2017</span>

    <ul>
  <li>Sutton - Temporal-Difference Learning- RLSS 2017.pd
https://drive.google.com/file/d/0BzUSSMdMszk6VE9kMkY2SzQzSW8/view?usp=drive_web</li>
  <li>Szepesvari - Theory of RL - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6U194Ym5jSnZQbGM/view?usp=drive_web</li>
  <li>Thomas - Safe Reinforcement Learning - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6TDRMRGRaM0dBcHM/view?usp=drive_web</li>
  <li>Why is Posterior Sampling Better than Optimism for Reinforcement
Learning? Ian Osband, Benjamin Van Roy</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/21/">
        RL II - Basic tutorial RLSS17
      </a>
    </h1>

    <span class="post-date">- 21 Nov 2017</span>

    <ul>
  <li>Hasselt - Deep Reinforcement Learning - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6UE5TbWdZekFXSE0/view?usp=drive_web</li>
  <li>Roux - RL in the Industry - RLSS 2017.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6bEprTUpCaHRrQ28/view</li>
  <li>Singh - Steps Towards Continual Learning.pdf
https://drive.google.com/file/d/0BzUSSMdMszk6YVhFUUNLZnZLSWs/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/16/">
        Generative III -  GAN and More
      </a>
    </h1>

    <span class="post-date">- 16 Nov 2017</span>

    <ul>
  <li>
    <p>Generalization and Equilibrium in Generative Adversarial Nets (GANs),
ICML17</p>
  </li>
  <li>
    <p>Generative Models and Model Criticism via Optimized Maximum Mean
Discrepancy, ICLR17</p>
  </li>
  <li>
    <p>Improving Generative Adversarial Networks with Denoising Feature
Matching, ICLR17</p>
  </li>
  <li>Stochastic Generative Hashing, Bo Dai, Ruiqi Guo, Sanjiv Kumar, Niao
He, Le Song, ICML17</li>
  <li>Robust Structured Estimation with Single-Index Models, ICML17</li>
  <li>Learning Hierarchical Features from Deep Generative Models, Shengjia
Zhao, Jiaming Song, Stefano Ermon ; PMLR 70:4091-4099</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/14/">
        Generative II - Deep Generative Models
      </a>
    </h1>

    <span class="post-date">- 14 Nov 2017</span>

    <ul>
  <li>
    <p>Courville - Generative Models II - DLSS 2017.  https://drive.google.com/file/d/0B_wzP_JlVFcKQ21udGpTSkh0aVk/view</p>
  </li>
  <li>
    <p>Johnson - Graphical Models and Deep Learning https://drive.google.com/file/d/0B6NHiPcsmak1RmZ3bmtFWUd5bjA/view?usp=drive_web</p>
  </li>
  <li>
    <p>Attend, Infer, Repeat: Fast Scene Understanding with Generative
Models, NIPS16</p>
  </li>
  <li>Parallel Multiscale Autoregressive Density Estimation, Scott Reed,
Aäron van den Oord, Nal Kalchbrenner, Ziyu Wang, Dan Belov, Nando de Freitas</li>
  <li>Generative Models and Model Criticism via Optimized Maximum Mean
Discrepancy, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/09/">
        Optimization IV -   DNN for Optimization
      </a>
    </h1>

    <span class="post-date">- 09 Nov 2017</span>

    <ul>
  <li>Axiomatic Attribution for Deep Networks, Mukund Sundararajan, Ankur
Taly, Qiqi Yan ; PMLR 70:3319-3328</li>
  <li>End-to-End Differentiable Adversarial Imitation Learning, ICML17</li>
  <li>Neural Optimizer Search with Reinforcement Learning, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/07/">
        Optimization III -   Optimization for DNN
      </a>
    </h1>

    <span class="post-date">- 07 Nov 2017</span>

    <ul>
  <li>Sharp Minima Can Generalize For Deep Nets, ICML17</li>
  <li>Forward and Reverse Gradient-Based Hyperparameter Optimization, ICML17</li>
  <li>Adaptive Neural Networks for Efficient Inference, ICML17</li>
  <li>Practical Gauss-Newton Optimisation for Deep Learning, ICML17</li>
  <li>
    <p>Professor Forcing: A New Algorithm for Training Recurrent Networks, NIPS16</p>
  </li>
  <li>Axiomatic Attribution for Deep Networks, Mukund Sundararajan, Ankur
Taly, Qiqi Yan ; PMLR 70:3319-3328</li>
  <li>End-to-End Differentiable Adversarial Imitation Learning, ICML17</li>
  <li>Neural Optimizer Search with Reinforcement Learning, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/11/02/">
        Optimization II -  DNN for Optimization
      </a>
    </h1>

    <span class="post-date">- 02 Nov 2017</span>

    <ul>
  <li>Batched High-dimensional Bayesian Optimization via Structural Kernel
Learning</li>
  <li>Optimization as a Model for Few-Shot Learning, ICLR17</li>
  <li>Neural Architecture Search with Reinforcement Learning, ICLR17</li>
  <li>Automated Curriculum Learning for Neural Networks, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/31/">
        Optimization I - Understanding DNN Optimization
      </a>
    </h1>

    <span class="post-date">- 31 Oct 2017</span>

    <ul>
  <li>
    <p>An overview of gradient optimization algorithms,
(https://arxiv.org/abs/1609.04747)</p>
  </li>
  <li>Johnson - Automatic Differentiation.p
https://drive.google.com/file/d/0B6NHiPcsmak1ckYxR2hmRGdzdFk/view</li>
  <li>Osborne - Probabilistic numerics for deep learning - DLSS 2017.pdf
https://drive.google.com/file/d/0B2A1tnmq5zQdWHBYOFctNi1KdVU/view</li>
  <li>How to Escape Saddle Points Efficiently, Chi Jin (UC Berkeley) · Rong
Ge (Duke University) · Praneeth Netrapalli (Microsoft Research) · Sham
M. Kakade (University of Washington) · Michael Jordan (UC Berkeley), ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/26/">
        Reliable Applications VI - Robustness
      </a>
    </h1>

    <span class="post-date">- 26 Oct 2017</span>

    <ul>
  <li>Robustness of classifiers: from adversarial to random noise, NIPS16</li>
  <li>Examples are not Enough, Learn to Criticize! Model Criticism for
Interpretable Machine Learning, NIPS16</li>
  <li>Blind Attacks on Machine Learners, Alex Beatson*, Princeton
University; Zhaoran Wang, Princeton University; Han Liu, NIPS16</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/24/">
        Reliable Applications V - Understanding and Composing DNNs
      </a>
    </h1>

    <span class="post-date">- 24 Oct 2017</span>

    <ul>
  <li>Toward Deeper Understanding of Neural Networks: The Power of
Initialization and a Dual View on Expressivity, NIPS16</li>
  <li>Domain Separation Networks, NIPS16</li>
  <li>The Robustness of Estimator Composition, NIPS16</li>
  <li>Composing graphical models with neural networks for structured
representations and fast inference, NIPS16</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/19/">
        Reliable Applications IV - Robustness to Data
      </a>
    </h1>

    <span class="post-date">- 19 Oct 2017</span>

    <ul>
  <li>Data Noising as Smoothing in Neural Network Language Models (Ng), ICLR17</li>
  <li>On Detecting Adversarial Perturbations, ICLR17</li>
  <li>Delving into Transferable Adversarial Examples and Black-box Attacks,
ICLR17</li>
  <li>Parseval Networks: Improving Robustness to Adversarial Examples, ICML17</li>
  <li>Being Robust (in High Dimensions) Can Be Practical, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/17/">
        Reliable Applications III - Applications 2
      </a>
    </h1>

    <span class="post-date">- 17 Oct 2017</span>

    <ul>
  <li>Conditional Image Generation with Pixel CNN Decoders, NIPS16</li>
  <li>Learning to Query, Reason, and Answer Questions On Ambiguous Texts, ICLR17</li>
  <li>Visualizing Deep Neural Network Decisions: Prediction Difference
Analysis, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/12/">
        Reliable Applications II - Data
      </a>
    </h1>

    <span class="post-date">- 12 Oct 2017</span>

    <ul>
  <li>Measuring Sample Quality with Kernels,</li>
  <li>Semi-supervised Knowledge Transfer for Deep Learning from Private
Training Data, ICLR17</li>
  <li>Deep Learning with Differential Privacy,</li>
  <li>Privacy-Preserving Deep Learning, CCS15</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/10/">
        Reliable Applications I - Applications
      </a>
    </h1>

    <span class="post-date">- 10 Oct 2017</span>

    <ul>
  <li>Optimal Architectures in a Solvable Model of Deep Networks, NIPS16</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, Jakob Foerster, Justin Gilmer, Jan Chorowski, Jascha
Sohl-Dickstein, David Sussillo</li>
  <li>Axiomatic Attribution for Deep Networks, Ankur Taly, Qiqi Yan,Mukund
Sundararajan</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/05/">
        Structure VI - DNN with Adaptive Structures
      </a>
    </h1>

    <span class="post-date">- 05 Oct 2017</span>

    <ul>
  <li>AdaNet: Adaptive Structural Learning of Artificial Neural Networks, ICML17</li>
  <li>SplitNet: Learning to Semantically Split Deep Networks for Parameter
Reduction and Model Parallelization,</li>
  <li>Proximal Deep Structured Models, NIPS16</li>
  <li>Mollifying Networks, Bengio, ICLR17</li>
  <li>Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical
Representations of Tonal Music, ICLR17</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/10/03/">
        Structure V - DNN with Memory
      </a>
    </h1>

    <span class="post-date">- 03 Oct 2017</span>

    <ul>
  <li>Ask Me Anything: Dynamic Memory Networks for Natural Language
Processing, ICML17</li>
  <li>Can Active Memory Replace Attention? Łukasz Kaiser*, ; Samy Bengio, NIPS16</li>
  <li>Reasoning with Memory Augmented Neural Networks for Language
Comprehension, ICLR17</li>
  <li>State-Frequency Memory Recurrent Neural Networks, ICML17</li>
  <li>Reasoning with Memory Augmented Neural Networks for Language
Comprehension, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/28/">
        Structure IV - DNN with Attention 2
      </a>
    </h1>

    <span class="post-date">- 28 Sep 2017</span>

    <ul>
  <li>Paying More Attention to Attention: Improving the Performance of
Convolutional Neural Networks via Attention Transfer, ICLR17</li>
  <li>Bidirectional Attention Flow for Machine Comprehension, ICLR17</li>
  <li>Dynamic Coattention Networks For Question Answering, ICLR17</li>
  <li>Structured Attention Networks, ICLR17</li>
  <li>Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive
Transfer from multiple sources in the same domain, ICLR17</li>
  <li>An Information-Theoretic Framework for Fast and Robust Unsupervised
Learning via Neural Population Infomax, ICLR17</li>
  <li>Image-to-Markup Generation with Coarse-to-Fine Attention, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/26/">
        Structure III - DNN with Attention
      </a>
    </h1>

    <span class="post-date">- 26 Sep 2017</span>

    <ul>
  <li>Paying More Attention to Attention: Improving the Performance of
Convolutional Neural Networks via Attention Transfer, ICLR17</li>
  <li>Bidirectional Attention Flow for Machine Comprehension, ICLR17</li>
  <li>Dynamic Coattention Networks For Question Answering, ICLR17</li>
  <li>Structured Attention Networks, ICLR17</li>
  <li>Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive
Transfer from multiple sources in the same domain, ICLR17</li>
  <li>An Information-Theoretic Framework for Fast and Robust Unsupervised
Learning via Neural Population Infomax, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/21/">
        Structure II - DNN with Varying Structures
      </a>
    </h1>

    <span class="post-date">- 21 Sep 2017</span>

    <ul>
  <li>Outrageously Large Neural Networks: The Sparsely-Gated
Mixture-of-Experts Layer, (Dean), ICLR17</li>
  <li>Nonparametric Neural Networks, ICLR17</li>
  <li>
    <p>Sequence Modeling via Segmentations,</p>
  </li>
  <li>Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical
Representations of Tonal Music, ICLR17</li>
  <li>Input Switched Affine Networks: An RNN Architecture Designed for
Interpretability, ICML17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/19/">
        Structure I - Varying DNN structures for an application
      </a>
    </h1>

    <span class="post-date">- 19 Sep 2017</span>

    <ul>
  <li>Making Neural Programming Architectures Generalize via Recursion, ICLR17</li>
  <li>Optimization as a Model for Few-Shot Learning, ICLR17</li>
  <li>Learning End-to-End Goal-Oriented Dialog, ICLR17</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/14/">
        Foundations VI - More about Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 14 Sep 2017</span>

    <ul>
  <li>Large-Scale Evolution of Image Classifiers, Esteban Real, Sherry
Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc
V. Le, Alexey Kurakin ; PMLR 70:2902-2911</li>
  <li>A Closer Look at Memorization in Deep Networks, ICML17</li>
  <li>Dense Associative Memory for Pattern Recognition, NIPS16</li>
  <li>Learning Kernels with Random Features, Aman Sinha*, Stanford
University; John Duchi,</li>
  <li>Learning Structured Sparsity in Deep Neural Networks, NIPS16</li>
  <li>Learning the Number of Neurons in Deep Networks, NIPS16</li>
  <li>Learning Deep Parsimonious Representations, NIPS16</li>
  <li>Sharir - Overlapping Architectures.pdf
https://drive.google.com/file/d/0B6NHiPcsmak1ZzVkci1EdVN2YkU/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/12/">
        Foundations V - More about Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 12 Sep 2017</span>

    <ul>
  <li>Large-Scale Evolution of Image Classifiers, Esteban Real, Sherry
Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc
V. Le, Alexey Kurakin ; PMLR 70:2902-2911</li>
  <li>A Closer Look at Memorization in Deep Networks, ICML17</li>
  <li>Dense Associative Memory for Pattern Recognition, NIPS16</li>
  <li>Learning Kernels with Random Features, Aman Sinha*, Stanford
University; John Duchi,</li>
  <li>Learning Structured Sparsity in Deep Neural Networks, NIPS16</li>
  <li>Learning the Number of Neurons in Deep Networks, NIPS16</li>
  <li>Learning Deep Parsimonious Representations, NIPS16</li>
  <li>Sharir - Overlapping Architectures.pdf
https://drive.google.com/file/d/0B6NHiPcsmak1ZzVkci1EdVN2YkU/view?usp=drive_web</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/07/">
        Foundations IV - Investigating Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 07 Sep 2017</span>

    <ul>
  <li>Geometry of Neural Network Loss Surfaces via Random Matrix Theory,
Jeffrey Pennington, Yasaman Bahri</li>
  <li>On the Expressive Power of Deep Neural Networks, Maithra Raghu, Ben
Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein</li>
  <li>Understanding deep learning requires rethinking generalization, ICLR17</li>
  <li>On Large-Batch Training for Deep Learning: Generalization Gap and
Sharp Minima, ICLR17</li>
  <li>Why Deep Neural Networks for Function Approximation?, ICLR17</li>
  <li>Equivariance Through Parameter-Sharing, Siamak Ravanbakhsh, Jeff
Schneider, Barnabás Póczos ; PMLR 70:2892-2901</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/09/05/">
        Foundations III - Investigating Behaviors of DNN
      </a>
    </h1>

    <span class="post-date">- 05 Sep 2017</span>

    <ul>
  <li>Geometry of Neural Network Loss Surfaces via Random Matrix Theory,
Jeffrey Pennington, Yasaman Bahri</li>
  <li>On the Expressive Power of Deep Neural Networks, Maithra Raghu, Ben
Poole, Surya Ganguli, Jon Kleinberg, Jascha Sohl-Dickstein</li>
  <li>Understanding deep learning requires rethinking generalization, ICLR17</li>
  <li>On Large-Batch Training for Deep Learning: Generalization Gap and
Sharp Minima, ICLR17</li>
  <li>Why Deep Neural Networks for Function Approximation?, ICLR17</li>
  <li>Equivariance Through Parameter-Sharing, Siamak Ravanbakhsh, Jeff
Schneider, Barnabás Póczos ; PMLR 70:2892-2901</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/31/">
        Generative I - GAN tutorial by Ian Goodfellow
      </a>
    </h1>

    <span class="post-date">- 31 Aug 2017</span>

    <h3 id="gan-tutorial-by-ian-goodfellow-nips-2016">GAN tutorial by Ian Goodfellow (NIPS 2016):</h3>
<ul>
  <li>https://arxiv.org/abs/1701.00160</li>
  <li>https://www.youtube.com/watch?v=AJVyzd0rqdc</li>
</ul>

<h3 id="goodfellow---generative-models-i---dlss-2017">Goodfellow - Generative Models I - DLSS 2017</h3>
<ul>
  <li>https://drive.google.com/file/d/0ByUKRdiCDK7-bTgxTGoxYjQ4NW8/view</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/29/">
        Reinforcement I - Pineau - RL Basic Concepts
      </a>
    </h1>

    <span class="post-date">- 29 Aug 2017</span>

    <h3 id="pineau---rl-basic-concepts">Pineau - RL Basic Concepts</h3>
<ul>
  <li>https://drive.google.com/file/d/0BzUSSMdMszk6bjl3eU5CVmU0cWs/view</li>
  <li>http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/</li>
  <li>http://videolectures.net/deeplearning2016_pineau_advanced_topics/</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/24/">
        Foundations II - Ganguli - Theoretical Neuroscience and Deep Learning DLSS16
      </a>
    </h1>

    <span class="post-date">- 24 Aug 2017</span>

    <h3 id="ganguli---theoretical-neuroscience-and-deep-learning-dlss16">Ganguli - Theoretical Neuroscience and Deep Learning DLSS16</h3>

<ul>
  <li>http://videolectures.net/deeplearning2016_ganguli_theoretical_neuroscience/</li>
</ul>

  </div>
  

  <div class="post">
    <h1 class="post-title">
      <a href="/deep2Read//2017/08/22/">
        Foundations I -Andrew Ng - Nuts and Bolts of Applying Deep Learning
      </a>
    </h1>

    <span class="post-date">- 22 Aug 2017</span>

    <h3 id="andrew-ng---nuts-and-bolts-of-applying-deep-learning">Andrew Ng - Nuts and Bolts of Applying Deep Learning:</h3>

<ul>
  <li>https://www.youtube.com/watch?v=F1ka6a13S9I</li>
</ul>

  </div>
  

</div>

</div>

    </div>

  </body>
</html>
